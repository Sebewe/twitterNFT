{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a8afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from opensea import OpenseaAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209d433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(client_dicts):\n",
    "    clients = []\n",
    "    for client_keys in client_dicts:\n",
    "        new_client = tweepy.Client(bearer_token=client_keys['bearer'],\n",
    "                      consumer_key=client_keys['consumer'],\n",
    "                      consumer_secret=client_keys['consumer secret'],\n",
    "                      access_token=client_keys['access'],\n",
    "                      access_token_secret=client_keys['access secret'])\n",
    "        clients.append(new_client)\n",
    "    return clients\n",
    "\n",
    "\n",
    "\n",
    "client0_keys = {\n",
    "    'consumer'        : 'ui99yaOkodk6mmp22W3xONbJk',\n",
    "    'consumer secret' : 'E5ISoLzpJRKZHWkJQ3EtVPuqBYcfq7Eo0Cvmrs3y5HYID2PM5Z',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAHbAZgEAAAAAWHWL%2Fvjp3wumMhCTvSzisowiYwI%3Dqa4zdgBWZecz96sL6r0QYwxbw121cKIhC9LpJzMCitPjd5NSWk',\n",
    "    'access'          : '1486493794170142721-wtfOb1QjBtBiGiFiPXApPl7rzgVrfD',\n",
    "    'access secret'   : 'zIevs1zeGnWGN9MsBY4gnPbhmEPQuhts1hOQOeGGBLEBZ'\n",
    "}\n",
    "\n",
    "client1_keys = {\n",
    "    'consumer'        : 'hEKzENpB1SiwL202jePES5QgD',\n",
    "    'consumer secret' : 'mobQjnKpSuUOqlgnWcF80ToWepnCmh8hVx8z08Es3sF1NCkVuG',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAPr2ZgEAAAAA2PjRO6V%2BSeVylV0SSmwIH6dJTK4%3DDyRjcdpz1GwcRpLevQqUmLtviMno9y80tAKaWOEz8i1JwDz52T',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "client2_keys = {\n",
    "    'consumer'        : 'XjXhQiY7tK78llw8I3Lj2mFBH',\n",
    "    'consumer secret' : 'KjHbnWsJJRx3jiDJY0kg3D2HgwL30SU9I54CB4YupTQGWRasEO',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAACD3ZgEAAAAACOLyhczBXrTN1SYWws8GUQSrk6c%3DRJwdn0R9eHyk2v0tZjMexXLsgMqUkGXreYCQty1Hmiliaon7GF',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "client3_keys = {\n",
    "    'consumer'        : '3o97ykbP5bl9zKTAjDVU8b1Z8',\n",
    "    'consumer secret' : 'lIx7g7uMmVOYZZYQzJlmwRWgaXY4pNbIlPoclDvzD3WrC04oyS',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAPcYZwEAAAAAaEVKqvvlyPuTQpPklhNc1RfEXTs%3DpIx6792tOeqBxMCbD5PSpXVvtnx3NMMkfIXVoRBAQyJuttuCkQ',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "client4_keys = {\n",
    "    'consumer'        : '6MoEG4SMyUEehSmKvx2AcyLtk',\n",
    "    'consumer secret' : 'PrEIzIL0y2ShhiqeL3NCWjEWSPTb48V8O2sBL6icEnl19SAOSX',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAHz3ZgEAAAAAa9kOrIzU4qh0Tk9%2FWTS9%2BiHED%2Fk%3Dm9QaWYBgEHa9C5rXeiHFHBWFr1OMK3fxDwZ1Ls5UrHK3Mfzmag',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "\n",
    "client5_keys = {\n",
    "    'consumer'        : 'oh7eP92fKhVuLxeU4HvYTKbVu',\n",
    "    'consumer secret' : 'ua3sz6AaI4vaqoLRsnvZYgcaI3mrJHcRxOoxeBYf0FoJIUhVwh',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAP8YZwEAAAAAsIgTOIfYr3fXomx%2BrHUe2tgmwOE%3DXMDXVlrFh64ycyMbnrTMcVuEwF6ZSzYhYpjvTRDcfYM6QLoKRl',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "\n",
    "client6_keys = {\n",
    "    'consumer'        : 'qsl2yBJwtuDbFHPwVZH8p98vZ',\n",
    "    'consumer secret' : 'MQPuNw8tIkpHflf4ueazXEe5fYWaqyErs19ADDtpdnf7R4Mr4j',\n",
    "    'bearer'          : 'AAAAAAAAAAAAAAAAAAAAAAYZZwEAAAAAHj2lsZ0iWLqX%2FMQwYg6JJIjlMs4%3D9i1DzI9p7WNXK2KuMLQZXWwHgPKSwW0BRWb6IvNSPnInpypHA8',\n",
    "    'access'          : '1486493794170142721-VlLKjzULa7f3gub1yEOfVr6fohbeJx',\n",
    "    'access secret'   : 'ykvyZedjVAs8N8Ddph2LqgRodpAFo10OUNWepBp10DdgA'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clients = create_clients([client0_keys, client0_keys, client2_keys, \n",
    "                          client3_keys, client4_keys, client5_keys, \n",
    "                          client6_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd0ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function just returns a user's following in a numpyarray\n",
    "the array is 2 dimensional:\n",
    "    1st dimension has 1 input for each user\n",
    "    2nd dimension is:\n",
    "        0 = user's username\n",
    "        1 = user's id\n",
    "        optional: 2 = user's profile name\n",
    "\"\"\"\n",
    "def get_following(clients, progress_bar=None, userID=None, username=None, contain_names=False):\n",
    "    if userID == None and username == None: #make sure we passed in a user\n",
    "        raise BaseException('get_following was ran without any identification')\n",
    "    \n",
    "    \n",
    "    \n",
    "    client_i = 0\n",
    "    while userID == None:\n",
    "        try:\n",
    "            client = clients[client_i]\n",
    "            userID = client.get_user(username=username).data.id\n",
    "        except Exception:\n",
    "            if client_i == len(clients)-1:\n",
    "                if type(progress_bar) != type(None):\n",
    "                    progress_bar.add_bar('Waiting For API', 15*6)\n",
    "                for i in range(15*6):\n",
    "                    sleep(10)\n",
    "                    progress_bar.update_progress('Waiting For API', i)\n",
    "                    progress_bar.write_to_screen()\n",
    "                client_i=0\n",
    "            else:\n",
    "                client_i+=1\n",
    "    \n",
    "    #get our data\n",
    "    user_following_raw = None\n",
    "    client_i = 0\n",
    "    while(user_following_raw == None):\n",
    "        try:\n",
    "            client = clients[client_i]\n",
    "            user_following_raw = client.get_users_following(userID, max_results=1000).data\n",
    "        except Exception:\n",
    "            if client_i == len(clients)-1:\n",
    "                if type(progress_bar) != type(None):\n",
    "                    progress_bar.add_bar('Waiting For API', 15*6)\n",
    "                for i in range(15*6):\n",
    "                    sleep(10)\n",
    "                    progress_bar.update_progress('Waiting For API', i)\n",
    "                    progress_bar.write_to_screen()\n",
    "                client_i=0\n",
    "            else:\n",
    "                client_i+=1\n",
    "    \n",
    "    #if we want names in the array, increase the size of our 2nd dimension\n",
    "    size = 3 if contain_names else 2\n",
    "    \n",
    "    #put it into a numpy array, \n",
    "    user_following= np.empty(shape=(0, size), dtype=object)\n",
    "    for i, user_data in enumerate(user_following_raw):\n",
    "        user_data_list = [user_data.username, user_data.id]\n",
    "        if(contain_names):\n",
    "            user_data_list.append(user_data.name)\n",
    "        user_following = np.append(user_following, [user_data_list], axis=0)\n",
    "        \n",
    "        \n",
    "    return user_following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9f07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mish_following = get_following(clients, username='frogdeveloper', contain_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc68dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class progress_bars:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.progress_bars = {}\n",
    "    \n",
    "    def add_bar(self, bar_name, prog_max, prog=0, num_bars=50):\n",
    "        self.progress_bars[bar_name] = {\n",
    "            'prog': prog,\n",
    "            'prog_max': prog_max,\n",
    "            'num_bars': num_bars\n",
    "        }\n",
    "    \n",
    "    def del_bar(self, bar_name):\n",
    "        del self.progress_bars[bar_name]\n",
    "    \n",
    "    def update_progress(self, bar_name, prog):\n",
    "        self.progress_bars[bar_name]['prog'] = prog\n",
    "    \n",
    "    def write_to_screen(self):\n",
    "        output = ''\n",
    "        for key in self.progress_bars.keys():\n",
    "            bar = self.progress_bars[key]\n",
    "            \n",
    "            num_bars = int((bar['prog']/bar['prog_max'])*bar['num_bars'])\n",
    "            num_spaces = bar['num_bars']-num_bars\n",
    "            percent_complete = np.round(bar['prog']/bar['prog_max']*100, 2)\n",
    "            \n",
    "            bar = key+': <'+('|'*num_bars)+(' '*num_spaces)+'> ('+str(percent_complete)+'%) \\n'\n",
    "            output += bar\n",
    "        clear_output()\n",
    "        print(output)\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5123811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "aggregate_IDs begins a search at start_user and will collect at least (min_IDs)\n",
    "twitter ID's that have 'eth' in their name.\n",
    "it searches by looking through all of the followers and aggregating their followers until\n",
    "the desired amount is reached.\n",
    "\"\"\"\n",
    "\n",
    "def aggregate_IDs(clients, start_userID=None, start_username=None, min_IDs=500, load_path=''):\n",
    "    prog_bar = progress_bars()\n",
    "    prog_bar.add_bar('ID Aggregation', min_IDs)\n",
    "    \n",
    "    start = time.time()\n",
    "    if load_path == '':\n",
    "        if start_userID == None and start_username == None:\n",
    "            raise BaseException('aggregate_users was called with no user to begin from')\n",
    "\n",
    "        client_i = 0\n",
    "        while start_userID == None:\n",
    "            try:\n",
    "                client = clients[client_i]\n",
    "                start_userID = client.get_user(username=start_username).data.id\n",
    "            except Exception:\n",
    "                if client_i == len(clients)-1:\n",
    "                    for sleep_count in range(15*60):\n",
    "                        sleep(1)\n",
    "                        update_bar(sleep_count, 15*60, message='waiting for API')\n",
    "                    client_i=0\n",
    "                else:\n",
    "                    client_i+=1\n",
    "        \n",
    "        IDs = np.empty(shape=(0,1), dtype=int)\n",
    "        IDs = np.append(IDs, start_userID)\n",
    "        \n",
    "        search_users = get_following(clients, userID=start_userID, contain_names=True, progress_bar=prog_bar)\n",
    "        index = 0\n",
    "        alpha_index = 1\n",
    "    else:\n",
    "        df = pd.read_csv(load_path)\n",
    "        IDs = df.get('IDs').to_numpy()\n",
    "        start_userID = IDs[-1]\n",
    "        \n",
    "        search_users = get_following(clients, userID=start_userID, contain_names=True, progress_bar=prog_bar)\n",
    "        index = 0\n",
    "        alpha_index = IDs.shape[0]-1\n",
    "    \n",
    "    \n",
    "    while len(IDs) < min_IDs:\n",
    "        user = search_users[index]\n",
    "        \n",
    "        if ('eth' in user[0] or 'eth' in user[2]) and (user[1] not in IDs):\n",
    "            IDs = np.append(IDs, user[1])\n",
    "            prog_bar.update_progress('ID Aggregation', IDs.shape[0])\n",
    "            if IDs.shape[0] % 100 == 0:\n",
    "                prog_bar.write_to_screen()\n",
    "        \n",
    "        index += 1\n",
    "        if index >= len(search_users):\n",
    "            df = pd.DataFrame()\n",
    "            df.insert(0, 'IDs', IDs)\n",
    "            df.to_csv('IDs.csv', header=True)\n",
    "            #if(alpha_index % 5 == 0):\n",
    "                #print('looking for more users:',alpha_index,'. curent total:', len(IDs),' time elapsed:', (time.time()-start))\n",
    "            search_users = get_following(clients, progress_bar=prog_bar, userID=IDs[alpha_index], contain_names=True)\n",
    "            index = 0\n",
    "            alpha_index += 1\n",
    "    \n",
    "    print('complete! total time elapsed:', np.round((time.time()-start)/60), 'minutes.')\n",
    "    return IDs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d43973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated_ids = aggregate_IDs(clients, start_username='frogdeveloper', min_IDs=10000)\n",
    "#aggregated_ids = aggregate_IDs(clients, load_path='usernames.csv', min_IDs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5321cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_tweets(clients, ID, prog_bar=None):\n",
    "    result = None\n",
    "    client_i = 0\n",
    "    while type(result) == type(None):\n",
    "        try:\n",
    "            result = clients[client_i].get_users_tweets(ID, max_results=100)\n",
    "            tweets = np.empty(shape=(0), dtype=object)\n",
    "            for tweet in result[0]:\n",
    "                tweets = np.append(tweets, tweet['text'])\n",
    "            return tweets\n",
    "        except Exception:\n",
    "            client_i += 1\n",
    "            if client_i >= len(clients):\n",
    "                client_i = 0\n",
    "                prog_bar.add_bar('Waiting For API', 15*6)\n",
    "                for i in range(15*6):\n",
    "                    prog_bar.update_progress('Waiting For API', i)\n",
    "                    prog_bar.write_to_screen()\n",
    "                    sleep(10)\n",
    "        \n",
    "        \n",
    "\n",
    "def pull_tweets(clients, IDs, finish=False, start_place=0):\n",
    "    progress_bar = progress_bars()\n",
    "    progress_bar.add_bar('Pulling Tweets', IDs.shape[0])\n",
    "    IDs = IDs[start_place:]\n",
    "    for i, ID in enumerate(IDs):\n",
    "        if i % 10 == 0:\n",
    "            progress_bar.update_progress('Pulling Tweets', i)\n",
    "            progress_bar.write_to_screen()\n",
    "        \n",
    "        df = pd.DataFrame(request_tweets(clients, ID, prog_bar=progress_bar))\n",
    "        df.to_csv('tweet_data/'+str(i+start_place)+'_'+str(ID)+'_tweets.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620d53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull_tweets(clients, aggregated_ids, start_place=2189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "454e22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rt_percentage(path):\n",
    "    prog_bar = progress_bars()\n",
    "    files = np.array(os.listdir(path))\n",
    "    prog_bar.add_bar('Scanning Data', files.shape[0])\n",
    "    total = 0\n",
    "    rt = 0\n",
    "    errs = np.empty(shape=(0), dtype=object)\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        if i % 50 == 0:\n",
    "            prog_bar.update_progress('Scanning Data', i)\n",
    "            prog_bar.write_to_screen()\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(path+file)\n",
    "            tweets = df.get('0')\n",
    "            total += tweets.shape[0]\n",
    "            for tweet in tweets:\n",
    "                if tweet[:2] == 'RT':\n",
    "                    rt += 1\n",
    "                    #return file\n",
    "        except Exception:\n",
    "            errs = np.append(errs, file)\n",
    "\n",
    "            \n",
    "    return total, rt/total, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "237406d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Data: <||||||||||||||||||||||||||||||||||||||||||||||||| > (99.89%) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_total, rt_ratio, errs = get_rt_percentage('tweet_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e6f9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empties(path, errs):\n",
    "    for err in errs:\n",
    "        os.remove(path+err)\n",
    "remove_empties('tweet_data/', errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cd3e496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(961857, 0.31505514853039485)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_total, rt_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25174028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86462f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
